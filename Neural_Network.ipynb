{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9732096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014e9314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USGG10YR</th>\n",
       "      <th>GDBR10</th>\n",
       "      <th>GUKG10</th>\n",
       "      <th>GFRN10</th>\n",
       "      <th>GACGB10</th>\n",
       "      <th>GCAN10YR</th>\n",
       "      <th>GNZGB10</th>\n",
       "      <th>JGBS10</th>\n",
       "      <th>GSWISS10</th>\n",
       "      <th>GNOR10YR</th>\n",
       "      <th>GBTPGR10</th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>GBPUSD</th>\n",
       "      <th>USDCAD</th>\n",
       "      <th>AUDUSD</th>\n",
       "      <th>NZDUSD</th>\n",
       "      <th>USDJPY</th>\n",
       "      <th>USDNOK</th>\n",
       "      <th>USDCHF</th>\n",
       "      <th>USGG12M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>4.2003</td>\n",
       "      <td>2.298</td>\n",
       "      <td>3.933</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.468</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>1.2623</td>\n",
       "      <td>1.3540</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>151.35</td>\n",
       "      <td>10.8260</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>5.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>4.2003</td>\n",
       "      <td>2.298</td>\n",
       "      <td>3.933</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.468</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>1.2624</td>\n",
       "      <td>1.3540</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>151.38</td>\n",
       "      <td>10.8567</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>5.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>4.1903</td>\n",
       "      <td>2.292</td>\n",
       "      <td>3.932</td>\n",
       "      <td>2.789</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.440</td>\n",
       "      <td>4.567</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.689</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.613</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>1.2640</td>\n",
       "      <td>1.3568</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>151.33</td>\n",
       "      <td>10.7797</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>4.9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>4.2316</td>\n",
       "      <td>2.350</td>\n",
       "      <td>3.971</td>\n",
       "      <td>2.835</td>\n",
       "      <td>4.025</td>\n",
       "      <td>3.498</td>\n",
       "      <td>4.565</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.723</td>\n",
       "      <td>3.606</td>\n",
       "      <td>3.653</td>\n",
       "      <td>1.0831</td>\n",
       "      <td>1.2628</td>\n",
       "      <td>1.3584</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>151.56</td>\n",
       "      <td>10.7568</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>4.9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>4.2454</td>\n",
       "      <td>2.372</td>\n",
       "      <td>3.988</td>\n",
       "      <td>2.850</td>\n",
       "      <td>4.006</td>\n",
       "      <td>3.489</td>\n",
       "      <td>4.502</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.680</td>\n",
       "      <td>3.599</td>\n",
       "      <td>3.694</td>\n",
       "      <td>1.0837</td>\n",
       "      <td>1.2636</td>\n",
       "      <td>1.3586</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>151.42</td>\n",
       "      <td>10.7165</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>4.9587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            USGG10YR  GDBR10  GUKG10  GFRN10  GACGB10  GCAN10YR  GNZGB10  \\\n",
       "Date                                                                       \n",
       "2024-03-29    4.2003   2.298   3.933   2.809    3.962     3.468    4.540   \n",
       "2024-03-28    4.2003   2.298   3.933   2.809    3.962     3.468    4.540   \n",
       "2024-03-27    4.1903   2.292   3.932   2.789    4.000     3.440    4.567   \n",
       "2024-03-26    4.2316   2.350   3.971   2.835    4.025     3.498    4.565   \n",
       "2024-03-25    4.2454   2.372   3.988   2.850    4.006     3.489    4.502   \n",
       "\n",
       "            JGBS10  GSWISS10  GNOR10YR  GBTPGR10  EURUSD  GBPUSD  USDCAD  \\\n",
       "Date                                                                       \n",
       "2024-03-29   0.750     0.687     3.572     3.681  1.0790  1.2623  1.3540   \n",
       "2024-03-28   0.730     0.687     3.572     3.681  1.0789  1.2624  1.3540   \n",
       "2024-03-27   0.738     0.689     3.572     3.613  1.0828  1.2640  1.3568   \n",
       "2024-03-26   0.757     0.723     3.606     3.653  1.0831  1.2628  1.3584   \n",
       "2024-03-25   0.752     0.680     3.599     3.694  1.0837  1.2636  1.3586   \n",
       "\n",
       "            AUDUSD  NZDUSD  USDJPY   USDNOK  USDCHF  USGG12M  \n",
       "Date                                                          \n",
       "2024-03-29  0.6521  0.5980  151.35  10.8260  0.9014   5.0238  \n",
       "2024-03-28  0.6516  0.5973  151.38  10.8567  0.9017   5.0238  \n",
       "2024-03-27  0.6535  0.6004  151.33  10.7797  0.9038   4.9877  \n",
       "2024-03-26  0.6533  0.6004  151.56  10.7568  0.9040   4.9882  \n",
       "2024-03-25  0.6540  0.6003  151.42  10.7165  0.8994   4.9587  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicts to identify which countries go with which tickers (all are 10-year Govt yields)\n",
    "codes = {}\n",
    "codes['US'] = 'USGG10YR'\n",
    "codes['Germany'] = 'GDBR10'\n",
    "codes['UK'] = 'GUKG10'\n",
    "codes['France'] = 'GFRN10'\n",
    "codes['Australia'] = 'GACGB10'\n",
    "codes['Canada'] = 'GCAN10YR'\n",
    "codes['New Zealand'] = 'GNZGB10'\n",
    "codes['Japan'] = 'JGBS10'\n",
    "codes['Switzerland'] = 'GSWISS10'\n",
    "codes['Norway'] = 'GNOR10YR'\n",
    "codes['Italy'] = 'GBTPGR10'\n",
    "\n",
    "codes_back = {}\n",
    "for key, value in codes.items():\n",
    "    codes_back[value] = key\n",
    "\n",
    "sheet_names = pd.ExcelFile('G10_RV.xlsx').sheet_names\n",
    "\n",
    "# Combining data into single df\n",
    "for i, x in enumerate(sheet_names):\n",
    "    if i == 0:\n",
    "        df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        df.columns = ['Date', x]\n",
    "    else:\n",
    "        new_df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        new_df.columns = ['Date', x]\n",
    "        df = df.merge(new_df, on='Date', how='outer')\n",
    "\n",
    "# Filling in missing days with previous observations, defining which columns are rates we want\n",
    "df = df.set_index('Date')\n",
    "df = df.resample('D').asfreq()\n",
    "df = df.ffill()\n",
    "df = df[::-1].dropna()\n",
    "rates_tickers = df.columns[:11]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0af0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 679us/step - loss: 0.0148\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 517us/step - loss: 0.0085\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 583us/step - loss: 0.0065\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 491us/step - loss: 0.0051\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 456us/step - loss: 0.0043\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 444us/step - loss: 0.0039\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 453us/step - loss: 0.0036\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 460us/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 439us/step - loss: 0.0035\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 454us/step - loss: 0.0034\n",
      "34/34 [==============================] - 0s 349us/step\n",
      "15/15 [==============================] - 0s 468us/step\n",
      "US training r2: 0.8615524168181401\n",
      "US training r2: 0.834433222053309\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 814us/step - loss: 0.0042\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 723us/step - loss: 0.0019\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 727us/step - loss: 0.0014\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 716us/step - loss: 0.0012\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 640us/step - loss: 0.0010\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 702us/step - loss: 8.7950e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 934us/step - loss: 7.9089e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 556us/step - loss: 7.2972e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 468us/step - loss: 6.5867e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.5246e-04\n",
      "34/34 [==============================] - 0s 351us/step\n",
      "15/15 [==============================] - 0s 380us/step\n",
      "Germany training r2: 0.9715756724083718\n",
      "Germany training r2: 0.9440450623418564\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 540us/step - loss: 0.0284\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 452us/step - loss: 0.0120\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 453us/step - loss: 0.0111\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 443us/step - loss: 0.0106\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 463us/step - loss: 0.0101\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 422us/step - loss: 0.0097\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 459us/step - loss: 0.0093\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 480us/step - loss: 0.0092\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 436us/step - loss: 0.0087\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 446us/step - loss: 0.0084\n",
      "34/34 [==============================] - 0s 343us/step\n",
      "15/15 [==============================] - 0s 370us/step\n",
      "UK training r2: 0.747987419038057\n",
      "UK training r2: 0.6711628505218042\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 478us/step - loss: 0.0148\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 490us/step - loss: 0.0035\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 450us/step - loss: 0.0020\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 439us/step - loss: 0.0014\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 433us/step - loss: 0.0011\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 441us/step - loss: 9.0410e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.9396e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.4096e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 455us/step - loss: 6.7682e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 433us/step - loss: 6.4820e-04\n",
      "34/34 [==============================] - 0s 345us/step\n",
      "15/15 [==============================] - 0s 375us/step\n",
      "France training r2: 0.9741363274480291\n",
      "France training r2: 0.9773519059759791\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 542us/step - loss: 0.0146\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 456us/step - loss: 0.0086\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 466us/step - loss: 0.0080\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 431us/step - loss: 0.0076\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 451us/step - loss: 0.0073\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 432us/step - loss: 0.0070\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 477us/step - loss: 0.0068\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 435us/step - loss: 0.0066\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 440us/step - loss: 0.0065\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 454us/step - loss: 0.0063\n",
      "34/34 [==============================] - 0s 371us/step\n",
      "15/15 [==============================] - 0s 387us/step\n",
      "Australia training r2: 0.7841692225789946\n",
      "Australia training r2: 0.7670614360777499\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 594us/step - loss: 0.0106\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 564us/step - loss: 0.0056\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 560us/step - loss: 0.0046\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 508us/step - loss: 0.0041\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 517us/step - loss: 0.0038\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 501us/step - loss: 0.0036\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 434us/step - loss: 0.0035\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 433us/step - loss: 0.0033\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 470us/step - loss: 0.0032\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 428us/step - loss: 0.0031\n",
      "34/34 [==============================] - 0s 352us/step\n",
      "15/15 [==============================] - 0s 412us/step\n",
      "Canada training r2: 0.8655547504857087\n",
      "Canada training r2: 0.7817056526374146\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0122\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 612us/step - loss: 0.0112\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 457us/step - loss: 0.0108\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 505us/step - loss: 0.0104\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 483us/step - loss: 0.0100\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 474us/step - loss: 0.0098\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 428us/step - loss: 0.0096\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 434us/step - loss: 0.0094\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 449us/step - loss: 0.0092\n",
      "34/34 [==============================] - 0s 344us/step\n",
      "15/15 [==============================] - 0s 382us/step\n",
      "New Zealand training r2: 0.6881028561425977\n",
      "New Zealand training r2: 0.6969165389156772\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 531us/step - loss: 0.0015\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 480us/step - loss: 8.1332e-04\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 491us/step - loss: 7.1819e-04\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 447us/step - loss: 6.6990e-04\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.2541e-04\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 448us/step - loss: 5.8558e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 451us/step - loss: 5.6054e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 462us/step - loss: 5.3620e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 470us/step - loss: 5.2323e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 782us/step - loss: 5.0765e-04\n",
      "34/34 [==============================] - 0s 340us/step\n",
      "15/15 [==============================] - 0s 394us/step\n",
      "Japan training r2: 0.5551322245004551\n",
      "Japan training r2: 0.08002368750498268\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 510us/step - loss: 0.0122\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 472us/step - loss: 0.0049\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 499us/step - loss: 0.0040\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 490us/step - loss: 0.0036\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 614us/step - loss: 0.0032\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 738us/step - loss: 0.0030\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 679us/step - loss: 0.0028\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 469us/step - loss: 0.0027\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 468us/step - loss: 0.0028\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 436us/step - loss: 0.0025\n",
      "34/34 [==============================] - 0s 356us/step\n",
      "15/15 [==============================] - 0s 388us/step\n",
      "Switzerland training r2: 0.8558033094793104\n",
      "Switzerland training r2: 0.5371321997891539\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 516us/step - loss: 0.0120\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 461us/step - loss: 0.0081\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 477us/step - loss: 0.0075\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 446us/step - loss: 0.0070\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 454us/step - loss: 0.0067\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 441us/step - loss: 0.0065\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 438us/step - loss: 0.0062\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 425us/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 447us/step - loss: 0.0058\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 438us/step - loss: 0.0058\n",
      "34/34 [==============================] - 0s 619us/step\n",
      "15/15 [==============================] - 0s 390us/step\n",
      "Norway training r2: 0.7120077204056443\n",
      "Norway training r2: 0.6103755727199289\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 557us/step - loss: 0.0418\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 479us/step - loss: 0.0240\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 473us/step - loss: 0.0199\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 453us/step - loss: 0.0167\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 456us/step - loss: 0.0144\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 466us/step - loss: 0.0128\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 491us/step - loss: 0.0115\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 477us/step - loss: 0.0106\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 544us/step - loss: 0.0100\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 600us/step - loss: 0.0097\n",
      "34/34 [==============================] - 0s 389us/step\n",
      "15/15 [==============================] - 0s 405us/step\n",
      "Italy training r2: 0.8184714908128058\n",
      "Italy training r2: 0.8100225482947376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>ABS Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training r2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Testing r2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictor ABS Mean\n",
       "0            US      NaN\n",
       "1       Germany      NaN\n",
       "2            UK      NaN\n",
       "3        France      NaN\n",
       "4     Australia      NaN\n",
       "5        Canada      NaN\n",
       "6   New Zealand      NaN\n",
       "7         Japan      NaN\n",
       "8   Switzerland      NaN\n",
       "9        Norway      NaN\n",
       "10        Italy      NaN\n",
       "11                      \n",
       "12  Training r2         \n",
       "13   Testing r2         "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nn(t):\n",
    "    data = df[rates_tickers].copy()\n",
    "    # scaler = StandardScaler()\n",
    "    # data = scaler.fit_transform(original)\n",
    "\n",
    "    # Calculating our changes\n",
    "    for ticker in data:\n",
    "        data[f'{ticker}_c'] = data[ticker].diff(-t)\n",
    "\n",
    "    #Train, test split\n",
    "    data = data.dropna()\n",
    "    changes = data[[x for x in data if x.endswith('_c')]]\n",
    "    changes_training = changes[changes.index < '2023-1-1']\n",
    "    changes_testing = changes[changes.index >= '2023-1-1']\n",
    "    causalities = pd.DataFrame()\n",
    "    causalities['Predictor'] = [codes_back[x] for x in rates_tickers] + ['', 'Training r2', 'Testing r2']\n",
    "\n",
    "    # Building model and storing results for each rate as the target, making df to see results\n",
    "    for i, target in enumerate(changes.columns):\n",
    "        training_X = changes_training[[x for x in changes_training if x != target]]\n",
    "        training_y = changes_training[target]\n",
    "        testing_X = changes_testing[[x for x in changes_testing if x != target]]\n",
    "        testing_y = changes_testing[target]\n",
    "        \n",
    "        # Compile the model\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(32, activation='relu', input_shape=[training_X.shape[1]]),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(training_X, training_y, epochs=10)\n",
    "        \n",
    "        # Make predictions\n",
    "        training_prediction = model.predict(training_X)\n",
    "        testing_prediction = model.predict(testing_X)\n",
    "\n",
    "        training_r2 = r2_score(training_y, training_prediction)\n",
    "        testing_r2 = r2_score(testing_y, testing_prediction)\n",
    "        print(f'{codes_back[target[:-2]]} training r2: {training_r2}')\n",
    "        print(f'{codes_back[target[:-2]]} training r2: {testing_r2}')\n",
    "        # coefficients = [round(x,2) for x in model.coef_]\n",
    "        # coefficients.insert(i, None)\n",
    "        # coefficients.insert(len(coefficients), '')\n",
    "        # coefficients.insert(len(coefficients), round(training_r2, 2))\n",
    "        # coefficients.insert(len(coefficients), round(testing_r2, 2))\n",
    "        # causalities[f'y: {codes_back[target[:-2]]}'] = coefficients\n",
    "    causalities['ABS Mean'] = [causalities.iloc[i, 1:].dropna().abs().mean() for i in range(11)] + ['', '', '']\n",
    "    \n",
    "    return causalities\n",
    "\n",
    "nn(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "G10_RV",
   "language": "python",
   "name": "g10_rv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
