{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9732096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014e9314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USGG10YR</th>\n",
       "      <th>GDBR10</th>\n",
       "      <th>GUKG10</th>\n",
       "      <th>GFRN10</th>\n",
       "      <th>GACGB10</th>\n",
       "      <th>GCAN10YR</th>\n",
       "      <th>GNZGB10</th>\n",
       "      <th>JGBS10</th>\n",
       "      <th>GSWISS10</th>\n",
       "      <th>GNOR10YR</th>\n",
       "      <th>GBTPGR10</th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>GBPUSD</th>\n",
       "      <th>USDCAD</th>\n",
       "      <th>AUDUSD</th>\n",
       "      <th>NZDUSD</th>\n",
       "      <th>USDJPY</th>\n",
       "      <th>USDNOK</th>\n",
       "      <th>USDCHF</th>\n",
       "      <th>USGG12M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>4.2003</td>\n",
       "      <td>2.298</td>\n",
       "      <td>3.933</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.468</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>1.2623</td>\n",
       "      <td>1.3540</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>151.35</td>\n",
       "      <td>10.8260</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>5.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>4.2003</td>\n",
       "      <td>2.298</td>\n",
       "      <td>3.933</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.468</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>1.2624</td>\n",
       "      <td>1.3540</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>151.38</td>\n",
       "      <td>10.8567</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>5.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>4.1903</td>\n",
       "      <td>2.292</td>\n",
       "      <td>3.932</td>\n",
       "      <td>2.789</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.440</td>\n",
       "      <td>4.567</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.689</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.613</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>1.2640</td>\n",
       "      <td>1.3568</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>151.33</td>\n",
       "      <td>10.7797</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>4.9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>4.2316</td>\n",
       "      <td>2.350</td>\n",
       "      <td>3.971</td>\n",
       "      <td>2.835</td>\n",
       "      <td>4.025</td>\n",
       "      <td>3.498</td>\n",
       "      <td>4.565</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.723</td>\n",
       "      <td>3.606</td>\n",
       "      <td>3.653</td>\n",
       "      <td>1.0831</td>\n",
       "      <td>1.2628</td>\n",
       "      <td>1.3584</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>151.56</td>\n",
       "      <td>10.7568</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>4.9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>4.2454</td>\n",
       "      <td>2.372</td>\n",
       "      <td>3.988</td>\n",
       "      <td>2.850</td>\n",
       "      <td>4.006</td>\n",
       "      <td>3.489</td>\n",
       "      <td>4.502</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.680</td>\n",
       "      <td>3.599</td>\n",
       "      <td>3.694</td>\n",
       "      <td>1.0837</td>\n",
       "      <td>1.2636</td>\n",
       "      <td>1.3586</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>151.42</td>\n",
       "      <td>10.7165</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>4.9587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            USGG10YR  GDBR10  GUKG10  GFRN10  GACGB10  GCAN10YR  GNZGB10  \\\n",
       "Date                                                                       \n",
       "2024-03-29    4.2003   2.298   3.933   2.809    3.962     3.468    4.540   \n",
       "2024-03-28    4.2003   2.298   3.933   2.809    3.962     3.468    4.540   \n",
       "2024-03-27    4.1903   2.292   3.932   2.789    4.000     3.440    4.567   \n",
       "2024-03-26    4.2316   2.350   3.971   2.835    4.025     3.498    4.565   \n",
       "2024-03-25    4.2454   2.372   3.988   2.850    4.006     3.489    4.502   \n",
       "\n",
       "            JGBS10  GSWISS10  GNOR10YR  GBTPGR10  EURUSD  GBPUSD  USDCAD  \\\n",
       "Date                                                                       \n",
       "2024-03-29   0.750     0.687     3.572     3.681  1.0790  1.2623  1.3540   \n",
       "2024-03-28   0.730     0.687     3.572     3.681  1.0789  1.2624  1.3540   \n",
       "2024-03-27   0.738     0.689     3.572     3.613  1.0828  1.2640  1.3568   \n",
       "2024-03-26   0.757     0.723     3.606     3.653  1.0831  1.2628  1.3584   \n",
       "2024-03-25   0.752     0.680     3.599     3.694  1.0837  1.2636  1.3586   \n",
       "\n",
       "            AUDUSD  NZDUSD  USDJPY   USDNOK  USDCHF  USGG12M  \n",
       "Date                                                          \n",
       "2024-03-29  0.6521  0.5980  151.35  10.8260  0.9014   5.0238  \n",
       "2024-03-28  0.6516  0.5973  151.38  10.8567  0.9017   5.0238  \n",
       "2024-03-27  0.6535  0.6004  151.33  10.7797  0.9038   4.9877  \n",
       "2024-03-26  0.6533  0.6004  151.56  10.7568  0.9040   4.9882  \n",
       "2024-03-25  0.6540  0.6003  151.42  10.7165  0.8994   4.9587  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicts to identify which countries go with which tickers (all are 10-year Govt yields)\n",
    "codes = {}\n",
    "codes['US'] = 'USGG10YR'\n",
    "codes['Germany'] = 'GDBR10'\n",
    "codes['UK'] = 'GUKG10'\n",
    "codes['France'] = 'GFRN10'\n",
    "codes['Australia'] = 'GACGB10'\n",
    "codes['Canada'] = 'GCAN10YR'\n",
    "codes['New Zealand'] = 'GNZGB10'\n",
    "codes['Japan'] = 'JGBS10'\n",
    "codes['Switzerland'] = 'GSWISS10'\n",
    "codes['Norway'] = 'GNOR10YR'\n",
    "codes['Italy'] = 'GBTPGR10'\n",
    "\n",
    "codes_back = {}\n",
    "for key, value in codes.items():\n",
    "    codes_back[value] = key\n",
    "\n",
    "sheet_names = pd.ExcelFile('G10_RV.xlsx').sheet_names\n",
    "\n",
    "# Combining data into single df\n",
    "for i, x in enumerate(sheet_names):\n",
    "    if i == 0:\n",
    "        df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        df.columns = ['Date', x]\n",
    "    else:\n",
    "        new_df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        new_df.columns = ['Date', x]\n",
    "        df = df.merge(new_df, on='Date', how='outer')\n",
    "\n",
    "# Filling in missing days with previous observations, defining which columns are rates we want\n",
    "df = df.set_index('Date')\n",
    "df = df.resample('D').asfreq()\n",
    "df = df.ffill()\n",
    "df = df[::-1].dropna()\n",
    "rates_tickers = df.columns[:11]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0af0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.0222\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 690us/step - loss: 0.0077\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 517us/step - loss: 0.0055\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 617us/step - loss: 0.0047\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0039\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "34/34 [==============================] - 0s 446us/step\n",
      "15/15 [==============================] - 0s 450us/step\n",
      "US training r2: 0.8601381795745187\n",
      "US training r2: 0.8343719147944564\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 696us/step - loss: 0.0071\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 784us/step - loss: 0.0021\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 622us/step - loss: 0.0013\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 801us/step - loss: 0.0010\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 733us/step - loss: 9.2169e-04\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 651us/step - loss: 8.2099e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 846us/step - loss: 7.7934e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 822us/step - loss: 7.3983e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 717us/step - loss: 6.7979e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.5258e-04\n",
      "34/34 [==============================] - 0s 377us/step\n",
      "15/15 [==============================] - 0s 527us/step\n",
      "Germany training r2: 0.9704888090017928\n",
      "Germany training r2: 0.9568742870653156\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 797us/step - loss: 0.0147\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 770us/step - loss: 0.0114\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 739us/step - loss: 0.0106\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 779us/step - loss: 0.0100\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 879us/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 831us/step - loss: 0.0093\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 902us/step - loss: 0.0091\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 763us/step - loss: 0.0087\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 841us/step - loss: 0.0085\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 807us/step - loss: 0.0085\n",
      "34/34 [==============================] - 0s 508us/step\n",
      "15/15 [==============================] - 0s 467us/step\n",
      "UK training r2: 0.7502852652621398\n",
      "UK training r2: 0.7075896861083577\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 706us/step - loss: 0.0053\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 691us/step - loss: 0.0018\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 869us/step - loss: 0.0013\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 971us/step - loss: 0.0011\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 748us/step - loss: 9.7832e-04\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 924us/step - loss: 8.7459e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 921us/step - loss: 7.8821e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 728us/step - loss: 7.2440e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 710us/step - loss: 6.9343e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.2357e-04\n",
      "34/34 [==============================] - 0s 639us/step\n",
      "15/15 [==============================] - 0s 517us/step\n",
      "France training r2: 0.9746298377170385\n",
      "France training r2: 0.9599646239143865\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.0142\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 863us/step - loss: 0.0079\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.0072\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 974us/step - loss: 0.0069\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 815us/step - loss: 0.0065\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 787us/step - loss: 0.0062\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 818us/step - loss: 0.0060\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 901us/step - loss: 0.0059\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 960us/step - loss: 0.0058\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 954us/step - loss: 0.0056\n",
      "34/34 [==============================] - 0s 567us/step\n",
      "15/15 [==============================] - 0s 430us/step\n",
      "Australia training r2: 0.8088729444256546\n",
      "Australia training r2: 0.7229707988125507\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 898us/step - loss: 0.0145\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 743us/step - loss: 0.0061\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 806us/step - loss: 0.0050\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 589us/step - loss: 0.0045\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 712us/step - loss: 0.0041\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.0039\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 699us/step - loss: 0.0036\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 775us/step - loss: 0.0035\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 652us/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 729us/step - loss: 0.0033\n",
      "34/34 [==============================] - 0s 399us/step\n",
      "15/15 [==============================] - 0s 420us/step\n",
      "Canada training r2: 0.8652364510791553\n",
      "Canada training r2: 0.7859237670758039\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.0238\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 843us/step - loss: 0.0138\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 619us/step - loss: 0.0116\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 840us/step - loss: 0.0105\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 747us/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 699us/step - loss: 0.0096\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 680us/step - loss: 0.0096\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 689us/step - loss: 0.0093\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 797us/step - loss: 0.0091\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 803us/step - loss: 0.0091\n",
      "34/34 [==============================] - 0s 428us/step\n",
      "15/15 [==============================] - 0s 795us/step\n",
      "New Zealand training r2: 0.6984886708684332\n",
      "New Zealand training r2: 0.673392817712861\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 743us/step - loss: 0.0014\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 715us/step - loss: 8.0316e-04\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 552us/step - loss: 7.0833e-04\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 615us/step - loss: 6.5382e-04\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 788us/step - loss: 6.1543e-04\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 627us/step - loss: 5.8340e-04\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 662us/step - loss: 5.4468e-04\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 600us/step - loss: 5.4348e-04\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 646us/step - loss: 5.1782e-04\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 544us/step - loss: 5.1902e-04\n",
      "34/34 [==============================] - 0s 437us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Japan training r2: 0.5885091986149638\n",
      "Japan training r2: 0.06721872977505361\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 815us/step - loss: 0.0148\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.0058\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 709us/step - loss: 0.0043\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 718us/step - loss: 0.0037\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 595us/step - loss: 0.0034\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 693us/step - loss: 0.0032\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 703us/step - loss: 0.0031\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 562us/step - loss: 0.0029\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 769us/step - loss: 0.0028\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 687us/step - loss: 0.0027\n",
      "34/34 [==============================] - 0s 420us/step\n",
      "15/15 [==============================] - 0s 443us/step\n",
      "Switzerland training r2: 0.8458875037108395\n",
      "Switzerland training r2: 0.5343972330936615\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 741us/step - loss: 0.0120\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 740us/step - loss: 0.0082\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 693us/step - loss: 0.0075\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 648us/step - loss: 0.0072\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 682us/step - loss: 0.0070\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 761us/step - loss: 0.0068\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 762us/step - loss: 0.0065\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 588us/step - loss: 0.0063\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 763us/step - loss: 0.0063\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 640us/step - loss: 0.0059\n",
      "34/34 [==============================] - 0s 427us/step\n",
      "15/15 [==============================] - 0s 543us/step\n",
      "Norway training r2: 0.6913950788429353\n",
      "Norway training r2: 0.5623562635470485\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.0287\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 563us/step - loss: 0.0205\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 766us/step - loss: 0.0174\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 637us/step - loss: 0.0132\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 764us/step - loss: 0.0120\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 857us/step - loss: 0.0109\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 654us/step - loss: 0.0096\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 769us/step - loss: 0.0091\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 573us/step - loss: 0.0085\n",
      "34/34 [==============================] - 0s 433us/step\n",
      "15/15 [==============================] - 0s 452us/step\n",
      "Italy training r2: 0.8349196595866126\n",
      "Italy training r2: 0.8138631128648423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>ABS Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training r2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Testing r2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictor ABS Mean\n",
       "0            US      NaN\n",
       "1       Germany      NaN\n",
       "2            UK      NaN\n",
       "3        France      NaN\n",
       "4     Australia      NaN\n",
       "5        Canada      NaN\n",
       "6   New Zealand      NaN\n",
       "7         Japan      NaN\n",
       "8   Switzerland      NaN\n",
       "9        Norway      NaN\n",
       "10        Italy      NaN\n",
       "11                      \n",
       "12  Training r2         \n",
       "13   Testing r2         "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nn(t):\n",
    "    data = df[rates_tickers].copy()\n",
    "    # scaler = StandardScaler()\n",
    "    # data = scaler.fit_transform(original)\n",
    "\n",
    "    # Calculating our changes\n",
    "    for ticker in data:\n",
    "        data[f'{ticker}_c'] = data[ticker].diff(-t)\n",
    "\n",
    "    #Train, test split\n",
    "    data = data.dropna()\n",
    "    changes = data[[x for x in data if x.endswith('_c')]]\n",
    "    changes_training = changes[changes.index < '2023-1-1']\n",
    "    changes_testing = changes[changes.index >= '2023-1-1']\n",
    "    causalities = pd.DataFrame()\n",
    "    causalities['Predictor'] = [codes_back[x] for x in rates_tickers] + ['', 'Training r2', 'Testing r2']\n",
    "\n",
    "    # Building model and storing results for each rate as the target, making df to see results\n",
    "    for i, target in enumerate(changes.columns):\n",
    "        training_X = changes_training[[x for x in changes_training if x != target]]\n",
    "        training_y = changes_training[target]\n",
    "\n",
    "        testing_X = changes_testing[[x for x in changes_testing if x != target]]\n",
    "        testing_y = changes_testing[target]\n",
    "        \n",
    "        # Compile the model\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(32, activation='relu', input_shape=[training_X.shape[1]]),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(training_X, training_y, epochs=10)\n",
    "        \n",
    "        # Make predictions\n",
    "        training_prediction = model.predict(training_X)\n",
    "        testing_prediction = model.predict(testing_X)\n",
    "\n",
    "        training_r2 = r2_score(training_y, training_prediction)\n",
    "        testing_r2 = r2_score(testing_y, testing_prediction)\n",
    "        print(f'{codes_back[target[:-2]]} training r2: {training_r2}')\n",
    "        print(f'{codes_back[target[:-2]]} training r2: {testing_r2}')\n",
    "        # Get the weights of the last layer\n",
    "        # weights = model.get_layer(index=-1).get_weights()[0]\n",
    "        # coefficients = [round(x[0], 2) for x in weights]\n",
    "        # coefficients.insert(i, None)\n",
    "        # coefficients.insert(len(coefficients), '')\n",
    "        # coefficients.insert(len(coefficients), round(training_r2, 2))\n",
    "        # coefficients.insert(len(coefficients), round(testing_r2, 2))\n",
    "        # causalities[f'y: {codes_back[target[:-2]]}'] = coefficients\n",
    "    causalities['ABS Mean'] = [causalities.iloc[i, 1:].dropna().abs().mean() for i in range(11)] + ['', '', '']\n",
    "    \n",
    "    return causalities\n",
    "\n",
    "nn(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "G10_RV",
   "language": "python",
   "name": "g10_rv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
