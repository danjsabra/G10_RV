{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USGG10YR</th>\n",
       "      <th>GDBR10</th>\n",
       "      <th>GUKG10</th>\n",
       "      <th>GFRN10</th>\n",
       "      <th>GACGB10</th>\n",
       "      <th>GCAN10YR</th>\n",
       "      <th>GNZGB10</th>\n",
       "      <th>JGBS10</th>\n",
       "      <th>GSWISS10</th>\n",
       "      <th>GNOR10YR</th>\n",
       "      <th>GBTPGR10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>3.7608</td>\n",
       "      <td>3.373</td>\n",
       "      <td>4.016</td>\n",
       "      <td>3.592</td>\n",
       "      <td>5.621</td>\n",
       "      <td>3.565</td>\n",
       "      <td>5.843</td>\n",
       "      <td>1.329</td>\n",
       "      <td>2.009</td>\n",
       "      <td>4.147</td>\n",
       "      <td>4.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-12</th>\n",
       "      <td>4.5216</td>\n",
       "      <td>2.359</td>\n",
       "      <td>4.137</td>\n",
       "      <td>2.865</td>\n",
       "      <td>4.266</td>\n",
       "      <td>3.649</td>\n",
       "      <td>4.839</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.739</td>\n",
       "      <td>3.707</td>\n",
       "      <td>3.762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            USGG10YR  GDBR10  GUKG10  GFRN10  GACGB10  GCAN10YR  GNZGB10  \\\n",
       "Date                                                                       \n",
       "2010-01-05    3.7608   3.373   4.016   3.592    5.621     3.565    5.843   \n",
       "2024-04-12    4.5216   2.359   4.137   2.865    4.266     3.649    4.839   \n",
       "\n",
       "            JGBS10  GSWISS10  GNOR10YR  GBTPGR10  \n",
       "Date                                              \n",
       "2010-01-05   1.329     2.009     4.147     4.101  \n",
       "2024-04-12   0.864     0.739     3.707     3.762  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = {}\n",
    "codes['US'] = 'USGG10YR'\n",
    "codes['Germany'] = 'GDBR10'\n",
    "codes['UK'] = 'GUKG10'\n",
    "codes['France'] = 'GFRN10'\n",
    "codes['Australia'] = 'GACGB10'\n",
    "codes['Canada'] = 'GCAN10YR'\n",
    "codes['New Zealand'] = 'GNZGB10'\n",
    "codes['Japan'] = 'JGBS10'\n",
    "codes['Switzerland'] = 'GSWISS10'\n",
    "codes['Norway'] = 'GNOR10YR'\n",
    "codes['Italy'] = 'GBTPGR10'\n",
    "\n",
    "sheet_names = pd.ExcelFile('G10_RV.xlsx').sheet_names[:11]\n",
    "dfs = {x: pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']].rename(columns={'Last Price': x}) for x in sheet_names}\n",
    "df = pd.DataFrame({'Date': dfs[sheet_names[0]]['Date']})  \n",
    "\n",
    "for key in dfs:\n",
    "    df = pd.merge(df, dfs[key], on='Date', how='outer')\n",
    "\n",
    "df = df.set_index('Date').resample('D').asfreq().ffill().dropna()\n",
    "df.iloc[[0,-1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2: Training</th>\n",
       "      <th>r2: Testing</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>0.004994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.033285</td>\n",
       "      <td>0.002568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.062750</td>\n",
       "      <td>0.010910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.030771</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.060806</td>\n",
       "      <td>0.006913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.005132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.008112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.056568</td>\n",
       "      <td>0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.085525</td>\n",
       "      <td>0.018093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             r2: Training  r2: Testing       MAE       MSE\n",
       "Country                                                   \n",
       "US                   0.99         0.80  0.050682  0.004994\n",
       "Germany              0.99         0.88  0.033285  0.002568\n",
       "UK                   0.98         0.68  0.062750  0.010910\n",
       "France               0.98         0.88  0.030771  0.002765\n",
       "Australia            0.98         0.76  0.060806  0.006913\n",
       "Canada               0.98         0.80  0.050490  0.005132\n",
       "New Zealand          0.98         0.73  0.066748  0.008112\n",
       "Japan                0.97         0.61  0.018565  0.000772\n",
       "Switzerland          0.98         0.71  0.044952  0.004762\n",
       "Norway               0.97         0.72  0.056568  0.005880\n",
       "Italy                0.96         0.60  0.085525  0.018093\n",
       "Mean                 0.98         0.74  0.051000  0.006000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X = df.copy()\n",
    "training_y = df.copy()\n",
    "testing_X = df.copy()\n",
    "testing_y = df.copy()\n",
    "\n",
    "def predictor(method, target, t):\n",
    "    data = df.copy()\n",
    "    target = codes[target]\n",
    "    target_t = f'{target}_{t}'\n",
    "    ts = [1,5,10,25,50,100]\n",
    "\n",
    "    for x in data:\n",
    "        for z in ts:\n",
    "            data[f'{x}_{z}'] = df[x].diff(z)\n",
    "\n",
    "    data = data.dropna()\n",
    "    cutoff = '2020-1-1'\n",
    "    training = data[data.index < cutoff]\n",
    "    testing = data[data.index > cutoff]\n",
    "    training_X = training[[x for x in training if '_' in x and x != target_t]]\n",
    "    training_y = training[target_t]\n",
    "    testing_X = testing[[x for x in testing if '_' in x and x != target_t]]\n",
    "    testing_y = testing[target_t]\n",
    "    # scaler = StandardScaler()\n",
    "    # training_X = scaler.fit_transform(training_X)\n",
    "    # testing_X = scaler.transform(testing_X)\n",
    "    # model = tf.keras.models.Sequential([\n",
    "    #         tf.keras.layers.Dense(64, activation='relu', input_shape=[training_X.shape[1]]),\n",
    "    #         tf.keras.layers.Dropout(0.3),\n",
    "    #         tf.keras.layers.Dense(32, activation='relu'),\n",
    "    #         tf.keras.layers.Dropout(0.3),\n",
    "    #         tf.keras.layers.Dense(1)\n",
    "    # ])\n",
    "    # model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    rfr = RandomForestRegressor(random_state=34)\n",
    "    rfr.fit(training_X, training_y)\n",
    "    training_prediction = rfr.predict(training_X)\n",
    "    testing_prediction = rfr.predict(testing_X)\n",
    "    mae = mean_absolute_error(testing_y, testing_prediction)\n",
    "    mse = mean_squared_error(testing_y, testing_prediction)\n",
    "    training_accuracy = round(r2_score(training_y, training_prediction), 2)\n",
    "    testing_accuracy = round(r2_score(testing_y, testing_prediction), 2)\n",
    "    prediction = pd.DataFrame(testing[target].copy())\n",
    "    prediction['c_prediction'] = testing_prediction\n",
    "    prediction['prediction'] = prediction[target].shift(t) + prediction['c_prediction']\n",
    "    prediction = prediction[[target, 'prediction']].dropna()\n",
    "    return prediction, training_accuracy, testing_accuracy, mae, mse\n",
    "\n",
    "def performance(t):\n",
    "    performances = pd.DataFrame()\n",
    "    performances['Country'] = codes.keys()\n",
    "    results = performances['Country'].apply(lambda x: predictor('neural', x, t))  # get all results\n",
    "    performances['r2: Training'] = results.apply(lambda x: x[1])  # training_accuracy\n",
    "    performances['r2: Testing'] = results.apply(lambda x: x[2])  # testing_accuracy\n",
    "    performances['MAE'] = results.apply(lambda x: x[3])  # mean_absolute_error\n",
    "    performances['MSE'] = results.apply(lambda x: x[4])  # mean_square_error\n",
    "    performances = performances.set_index('Country')\n",
    "    nnte_mean = round(performances['r2: Training'].mean(), 2)\n",
    "    nntr_mean = round(performances['r2: Testing'].mean(), 2)\n",
    "    mae_mean = round(performances['MAE'].mean(), 3)\n",
    "    mse_mean = round(performances['MSE'].mean(), 3)\n",
    "    performances.loc['Mean'] = {'r2: Training': nnte_mean, 'r2: Testing': nntr_mean, 'MAE': mae_mean, 'MSE': mse_mean}\n",
    "    return performances\n",
    "\n",
    "performance(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, training_X, training_y):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 150)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf =  trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    score = cross_val_score(model, training_X, training_y, cv=5, scoring='neg_mean_squared',n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-24 19:43:53,036] A new study created in memory with name: no-name-3c162625-1120-4c77-abc9-106eda4ae145\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-04-24 19:43:53,041] Trial 0 failed with parameters: {'n_estimators': 76, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 3} because of the following error: InvalidParameterError(\"The 'scoring' parameter of cross_val_score must be a str among {'precision_weighted', 'explained_variance', 'neg_log_loss', 'f1_macro', 'r2', 'top_k_accuracy', 'v_measure_score', 'max_error', 'roc_auc_ovr_weighted', 'neg_mean_squared_error', 'neg_brier_score', 'positive_likelihood_ratio', 'adjusted_mutual_info_score', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'f1_weighted', 'average_precision', 'jaccard_samples', 'jaccard_micro', 'precision_micro', 'precision_samples', 'recall_samples', 'rand_score', 'neg_mean_gamma_deviance', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'jaccard_weighted', 'fowlkes_mallows_score', 'roc_auc_ovr', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'neg_median_absolute_error', 'balanced_accuracy', 'precision', 'jaccard_macro', 'mutual_info_score', 'neg_root_mean_squared_log_error', 'roc_auc', 'completeness_score', 'recall_micro', 'recall', 'neg_mean_poisson_deviance', 'precision_macro', 'homogeneity_score', 'neg_mean_absolute_percentage_error', 'f1', 'f1_micro', 'jaccard', 'recall_macro', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'neg_negative_likelihood_ratio', 'f1_samples', 'accuracy', 'recall_weighted'}, a callable or None. Got 'neg_mean_squared' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jv/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/m6/9b999tss1dv5ml49bs8bnqww0000gn/T/ipykernel_17861/1569812150.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, training_X, training_y), n_trials=200)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/m6/9b999tss1dv5ml49bs8bnqww0000gn/T/ipykernel_17861/1533330333.py\", line 9, in objective\n",
      "    score = cross_val_score(model, training_X, training_y, cv=5, scoring='neg_mean_squared',n_jobs=-1).mean()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jv/anaconda3/envs/neural_network/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 203, in wrapper\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jv/anaconda3/envs/neural_network/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'scoring' parameter of cross_val_score must be a str among {'precision_weighted', 'explained_variance', 'neg_log_loss', 'f1_macro', 'r2', 'top_k_accuracy', 'v_measure_score', 'max_error', 'roc_auc_ovr_weighted', 'neg_mean_squared_error', 'neg_brier_score', 'positive_likelihood_ratio', 'adjusted_mutual_info_score', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'f1_weighted', 'average_precision', 'jaccard_samples', 'jaccard_micro', 'precision_micro', 'precision_samples', 'recall_samples', 'rand_score', 'neg_mean_gamma_deviance', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'jaccard_weighted', 'fowlkes_mallows_score', 'roc_auc_ovr', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'neg_median_absolute_error', 'balanced_accuracy', 'precision', 'jaccard_macro', 'mutual_info_score', 'neg_root_mean_squared_log_error', 'roc_auc', 'completeness_score', 'recall_micro', 'recall', 'neg_mean_poisson_deviance', 'precision_macro', 'homogeneity_score', 'neg_mean_absolute_percentage_error', 'f1', 'f1_micro', 'jaccard', 'recall_macro', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'neg_negative_likelihood_ratio', 'f1_samples', 'accuracy', 'recall_weighted'}, a callable or None. Got 'neg_mean_squared' instead.\n",
      "[W 2024-04-24 19:43:53,043] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of cross_val_score must be a str among {'precision_weighted', 'explained_variance', 'neg_log_loss', 'f1_macro', 'r2', 'top_k_accuracy', 'v_measure_score', 'max_error', 'roc_auc_ovr_weighted', 'neg_mean_squared_error', 'neg_brier_score', 'positive_likelihood_ratio', 'adjusted_mutual_info_score', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'f1_weighted', 'average_precision', 'jaccard_samples', 'jaccard_micro', 'precision_micro', 'precision_samples', 'recall_samples', 'rand_score', 'neg_mean_gamma_deviance', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'jaccard_weighted', 'fowlkes_mallows_score', 'roc_auc_ovr', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'neg_median_absolute_error', 'balanced_accuracy', 'precision', 'jaccard_macro', 'mutual_info_score', 'neg_root_mean_squared_log_error', 'roc_auc', 'completeness_score', 'recall_micro', 'recall', 'neg_mean_poisson_deviance', 'precision_macro', 'homogeneity_score', 'neg_mean_absolute_percentage_error', 'f1', 'f1_micro', 'jaccard', 'recall_macro', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'neg_negative_likelihood_ratio', 'f1_samples', 'accuracy', 'recall_weighted'}, a callable or None. Got 'neg_mean_squared' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, training_X, training_y), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, training_X, training_y), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, training_X, training_y)\u001b[0m\n\u001b[1;32m      5\u001b[0m min_samples_leaf \u001b[38;5;241m=\u001b[39m  trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators, max_depth\u001b[38;5;241m=\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39mmin_samples_split, min_samples_leaf\u001b[38;5;241m=\u001b[39mmin_samples_leaf)\n\u001b[0;32m----> 9\u001b[0m score \u001b[38;5;241m=\u001b[39m cross_val_score(model, training_X, training_y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared\u001b[39m\u001b[38;5;124m'\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 203\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    204\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_network/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'scoring' parameter of cross_val_score must be a str among {'precision_weighted', 'explained_variance', 'neg_log_loss', 'f1_macro', 'r2', 'top_k_accuracy', 'v_measure_score', 'max_error', 'roc_auc_ovr_weighted', 'neg_mean_squared_error', 'neg_brier_score', 'positive_likelihood_ratio', 'adjusted_mutual_info_score', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'f1_weighted', 'average_precision', 'jaccard_samples', 'jaccard_micro', 'precision_micro', 'precision_samples', 'recall_samples', 'rand_score', 'neg_mean_gamma_deviance', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'jaccard_weighted', 'fowlkes_mallows_score', 'roc_auc_ovr', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'neg_median_absolute_error', 'balanced_accuracy', 'precision', 'jaccard_macro', 'mutual_info_score', 'neg_root_mean_squared_log_error', 'roc_auc', 'completeness_score', 'recall_micro', 'recall', 'neg_mean_poisson_deviance', 'precision_macro', 'homogeneity_score', 'neg_mean_absolute_percentage_error', 'f1', 'f1_micro', 'jaccard', 'recall_macro', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'neg_negative_likelihood_ratio', 'f1_samples', 'accuracy', 'recall_weighted'}, a callable or None. Got 'neg_mean_squared' instead."
     ]
    }
   ],
   "source": [
    "study.optimize(lambda trial: objective(trial, training_X, training_y), n_trials=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network",
   "language": "python",
   "name": "neural_network"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
