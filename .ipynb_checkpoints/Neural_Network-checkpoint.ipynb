{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9732096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014e9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicts to identify which countries go with which tickers (all are 10-year Govt yields)\n",
    "codes = {}\n",
    "codes['US'] = 'USGG10YR'\n",
    "codes['Germany'] = 'GDBR10'\n",
    "codes['UK'] = 'GUKG10'\n",
    "codes['France'] = 'GFRN10'\n",
    "codes['Australia'] = 'GACGB10'\n",
    "codes['Canada'] = 'GCAN10YR'\n",
    "codes['New Zealand'] = 'GNZGB10'\n",
    "codes['Japan'] = 'JGBS10'\n",
    "codes['Switzerland'] = 'GSWISS10'\n",
    "codes['Norway'] = 'GNOR10YR'\n",
    "codes['Italy'] = 'GBTPGR10'\n",
    "\n",
    "codes_back = {}\n",
    "for key, value in codes.items():\n",
    "    codes_back[value] = key\n",
    "\n",
    "sheet_names = pd.ExcelFile('G10_RV.xlsx').sheet_names\n",
    "\n",
    "# Combining data into single df\n",
    "for i, x in enumerate(sheet_names[:11]):\n",
    "    if i == 0:\n",
    "        df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        df.columns = ['Date', x]\n",
    "    else:\n",
    "        new_df = pd.read_excel('G10_RV.xlsx', sheet_name=x)[['Date', 'Last Price']]\n",
    "        new_df.columns = ['Date', x]\n",
    "        df = df.merge(new_df, on='Date', how='outer')\n",
    "\n",
    "# Filling in missing days with previous observations, defining which columns are rates we want\n",
    "df = df.set_index('Date')\n",
    "df = df.resample('D').asfreq()\n",
    "df = df.ffill()\n",
    "df = df[::-1].dropna()\n",
    "rates_tickers = df.columns[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0af0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = [1,5,10,25,50,100]\n",
    "\n",
    "def nn_multi(target, t):\n",
    "    target_t = f'{target}_{t}'\n",
    "    data = df[rates_tickers].copy()\n",
    "\n",
    "    print(\"First\")\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    predictions = pd.DataFrame()\n",
    "\n",
    "    print(\"Second\")\n",
    "    # Calculating our changes\n",
    "    for ticker in rates_tickers:\n",
    "        for x in t_values:\n",
    "            data[f'{ticker}_{x}'] = data[ticker].diff(-x)\n",
    "    print(\"Third\")\n",
    "\n",
    "    #Train, test split\n",
    "    data = data.dropna()\n",
    "    data_training = data[data.index < '2023-1-1'].copy()\n",
    "    data_testing = data[data.index >= '2023-1-1'].copy()\n",
    "    print(\"Fourth\")\n",
    "    training_X = data_training[[x for x in data_training if '_' in x and x != target_t]]\n",
    "    training_y = data_training[target_t]\n",
    "    print(\"Fifth\")\n",
    "    testing_X = data_testing[[x for x in data_testing if '_' in x and x != target_t]]\n",
    "    testing_y = data_testing[target_t]\n",
    "\n",
    "    print(\"Sixth\")\n",
    "    # Scale the training and testing data\n",
    "    training_X = scaler.fit_transform(training_X)\n",
    "    testing_X = scaler.transform(testing_X)\n",
    "    print(\"Seventh\")\n",
    "    # Compile the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(training_X.shape[1],)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    print(\"Eighth\")\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    print(\"Ninth\")\n",
    "    # # Define early stopping\n",
    "    # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # Train the model\n",
    "    # Train the model\n",
    "    model.fit(training_X, training_y, epochs=200)\n",
    "    \n",
    "    print(\"Tenth\")\n",
    "    # Make predictions\n",
    "    training_prediction = model.predict(training_X)\n",
    "    testing_prediction = model.predict(testing_X)\n",
    "    testing_r2 = r2_score(testing_y, testing_prediction)\n",
    "    r2 = round(testing_r2, 2)\n",
    "    data_testing['c_prediction'] = testing_prediction\n",
    "    prediction = data_testing[[target, target_t, 'c_prediction']].copy()\n",
    "    prediction['prediction'] = prediction[target].shift(-t) + prediction['c_prediction']\n",
    "    prediction = prediction[[target, 'prediction']].dropna()\n",
    "    return prediction, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd4e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "First\n",
      "Second\n",
      "Third\n",
      "Fourth\n",
      "Fifth\n",
      "Sixth\n",
      "Seventh\n",
      "Eighth\n",
      "Ninth\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jv/anaconda3/envs/G10_RV/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def t_eval(t):\n",
    "    print(\"1\")\n",
    "    r2s = pd.DataFrame()\n",
    "    print(\"2\")\n",
    "    r2s['Target'] = list(codes.keys())\n",
    "    print(\"3\")\n",
    "    r2s['r2: NN Multi'] = r2s['Target'].apply(lambda x: nn_multi(codes[x], t)[1])\n",
    "    print(\"4\")\n",
    "    r2s = r2s.set_index('Target')\n",
    "    print(\"5\")\n",
    "    return r2s\n",
    "\n",
    "t_eval(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbbd03-7ac1-4ec7-8f98-4421361cc4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "G10_RV",
   "language": "python",
   "name": "g10_rv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
